# Что такое динамическое программирование?



Оглавление



## Мотивация

Работа разработчика состоит из решения головоломок. Многие из этих головоломок имеют эффективное решение, но некоторые возможно решить только перебором всех возможных вариантов. По крайней мере, такое впечатление складывается при первом знакомстве с этими задачами. 

Решение полным перебором часто называют решением в лоб, методом грубой силы или наивным решением. Такие решения имеют очевидный минус — они очень затратны. Практические любое неоптимизированное решение перебором будет стоить экспоненциального времени, например O(2^n), где n — это количество элементов в нашей задаче. Такими элементами могут быть ячейки массива, узлы графа, объекты из предметной области — всё что угодно. 

Это очень плохое время работы. Настолько плохое, что никому и в голову не придёт запустить такой алгоритм даже на простых данных, ведь на решение такой задачи с сотней элементов потребуются тысячи, миллионы или миллиарды лет вычислений. А в реальной жизни нужно решать задачи с намного большим количеством элементов. Как же быть?

Дело в том, что многие задачи без эффективного алгоритма решения можно решить за привлекательное время с помощью одной хитрости. Имя ей — динамическое программирование! Но давайте обо всём по порядку…



## Динамическое программирование

Динамическое программирование это особый подход к решению задач. Основная его идея: оптимальное решение задачи можно собрать из решений её кусочков. В отличие от обычной рекурсии и решений по принципу “разделяй и властвуй”, решения задач в динамическом программировании обычно наращиваются с нуля, а не собираются из кусочков раздробленной исходной задачи.

Магия динамического программирования заключается в умном обращении с решениями подзадач. “Умный” в этом контексте значит “не решающий одну и ту же подзадачу дважды”. Для этого решения мелких подзадач должны заботливо учитываться в подходящей структуре данных. Для многих реальных алгоритмов динамического программирования этой структурой данных является таблица.

В самых простых случаях эта таблица будет состоять только из одной строки — аналогично обычному массиву. Эти случаи будут называться одномерным динамическим программированием, и потреблять O(n) памяти. Например, алгоритм эффективного вычисления чисел Фибоначчи использует простой массив для запоминания промежуточных результатов.

В самых распространённых случаях эта таблица будет выглядеть привычно, из строчек и столбиков. Обычная таблица, похожая на таблицы из Excel. Это называется двумерным динамическим программированием, которое при n строках и n столбцах таблицы будет потреблять O(n*n) = O(n^2) памяти. Чуть ниже будет подробно разобрана именно такая задача.

Бывают и более запутанные задачи, использующие для решения трёхмерные таблицы, но это уже экзотика — O(n^3) памяти выглядит не сильно симпатичнее экспоненциального времени выполнения наивного решения.

Что нужно, чтоб решить задачу динамически, помимо её исходных данных? Всего три вещи:

- Таблица, в которую будут вноситься промежуточные результаты. Один из них будет выбран в конце работы алгоритма в качестве ответа.
- Несколько простых правил по заполнению пустых ячеек таблицы, основываясь на значениях в уже заполненных ячейках. Универсального рецепта тут нет, и к каждой задаче требуется свой подход.
- Правило выбора финального решения после заполнения таблицы.

Много слов уже было сказано об идеях и принципах динамического программирования, но без разбора задачи — грош этой болтовне цена. Настало время наглядного примера.

## Пример решения задачи

Демонстрационным подопытным выступит классическая задача динамического программирования — Расстояние Левенштейна. Звучит немножко пугающе, но на самом деле это задача об трансформации одного слова в другое путём добавления, удаления и замены букв с минимальным количеством операций. 

Не будем забираться в математическую формулировку, лучше сформулируем задачу на пальцах.  

Наша задача: найти минимальное “расстояние” между двумя словами. Расстоянием в этом случае будет минимальное количество операций, которые нужно применить к первому слову, чтобы получить второе (или наоборот).

Доступных операции у нас три:

- insert — добавить одну букву в любое место в слове, в том числе в самое начало и в конец.
- delete — удалить одну букву из любого места в слове.
- replace — заменить одну букву на определённом месте на другую букву.

Все эти операции имеют равную стоимость: +1 к расстоянию между словами.

Возьмем для примера два простых слова, MONEY и MONKEY. Какое минимальное количество операций необходимо, чтоб превратить MONEY в MONKEY? Находчивый человеческий глаз быстро смекнёт, что одна: добавить букву K после между третьей и четвертой буквой.

Кажется очень простой задачей, правда? Попробуйте превратить слово SUNDAY в слово SATURDAY, и вы увидите, что количество комбинаций, которые нужно перебрать, потенциально очень велико. Если решать задачу в лоб, то можно перебрать все возможные комбинации, рекурсивно применяя каждую из трёх представленных операций к каждой букве слова. Каждая буква в первом слове будет порождать три ветки рекурсии, что приведет аж к O(3^n) операций в худшем случае. 

### Динамическое решение

Приступим к динамическому решению!

Для начала, создадим таблицу, и разместим исходные слова на её краях, оставив немножко свободного места. Второй столбик и вторую строчку буем использовать для пустых строк — их часто обозначают символом ε, читается epsilon. Аналог того, что вы имеете в виду, когда используете пустую строку на своём языке программирования: String eps = “”.

|       |  ε   |  S   |  A   |  T   |  U   |  R   |  D   |  A   |  Y   |
| :---: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
| **ε** |      |      |      |      |      |      |      |      |      |
| **S** |      |      |      |      |      |      |      |      |      |
| **U** |      |      |      |      |      |      |      |      |      |
| **N** |      |      |      |      |      |      |      |      |      |
| **D** |      |      |      |      |      |      |      |      |      |
| **A** |      |      |      |      |      |      |      |      |      |
| **Y** |      |      |      |      |      |      |      |      |      |

Теперь заполним второй столбик и вторую строчку, руководствуясь абсолютно интуитивными соображениями: как превратить пустую строку в какую-то строку? Конечно же, добавить в неё нужные символы! Например, чтоб перевести ε в SATU необходимо добавить букву S, букву A, букву T и букву U. Четыре операции. Что делать с превращением ε в ε (вторая строка, второй столбец)? Элементарно — ничего делать не нужно, ноль действий.

|       |  ε   |  S   |  A   |  T   |  U   |  R   |  D   |  A   |  Y   |
| :---: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
| **ε** |  0   |  1   |  2   |  3   |  4   |  5   |  6   |  7   |  8   |
| **S** |  1   |      |      |      |      |      |      |      |      |
| **U** |  2   |      |      |      |      |      |      |      |      |
| **N** |  3   |      |      |      |      |      |      |      |      |
| **D** |  4   |      |      |      |      |      |      |      |      |
| **A** |  5   |      |      |      |      |      |      |      |      |
| **Y** |  6   |      |      |      |      |      |      |      |      |

Теперь нужна система простых правил, с помощью которой мы сможем заполнить таблицу. Таблица будет именоваться D, а первая строчка и столбик останутся на её полях. Работать с таблицей мы будем, как с двухмерным массивом: D[0, 2] означают ячейку на пересечении нулевой строки и второго столбика. В нашем примере D[0, 2] = 2.

Также назовём слово по вертикали A, а слово по горизонтали B. Эта парочка нам нужна, чтоб иметь доступ к оригинальным словам на полях. Из-за дополнительных колонок в для ε индексы в A и B отличаются от индексов в таблице. Если быть точнее — они сдвинуты на единицу. A[0] = S, A[1] = U, A[2] = N, B[7] = Y, и так далее.

Наконец, создадим наше правило заполнения таблицы. Для каждой новой ячейки мы проверяем верхнюю, левую или лево верхнюю по диагонали соседние ячейки. Из трёх чисел будет выбрано наименьшее и записано в новую ячейку.

*TODO сделать картинкой:*

```
D[i, j] = minimum(
	D[i-1, j] + 1,                              // delete
	D[i, j-1] + 1,                              // insert 
	D[i-1, j-1] + (A[i-1] == B[j-1] ? 1 : 0)    // replace 
)  
```

Это, несомненно, самый неприятный и сложный момент в динамическом программировании: правила кажутся бессмысленными, не выходит собрать общую картину происходящего в голове. Давайте посмотрим на маленький кусочек таблицы, возможно, он прольёт свет на некоторые детали.

|       |  ε   |  S   |  A   |
| :---: | :--: | :--: | :--: |
| **ε** |  0   |  1   |  2   |
| **S** |  1   |      |      |
| **U** |  2   |      |      |

Что записать в ячейку D[1,1] как результат перехода из S в S? Интуитивно ясно, что для этого ничего делать и не нужно, ноль операций. Запишем ноль в ячейку. На что походит это значение, учитывая, что вычитать ничего нельзя? Среди соседей ноль есть только по диагонали.

|       |  ε   |  S   |  A   |
| :---: | :--: | :--: | :--: |
| **ε** |  0   |  1   |  2   |
| **S** |  1   |  0   |      |
| **U** |  2   |      |      |

Что записать в ячейку D[2,1] как результат перехода из SU в S? Нужно удалить букву U, значит, одна операция. По-сути, стоимость перехода из SU в S будет равно стоимости удаления буквы U и перехода из S в S (чья стоимость уже была посчитана и лежит в ячейке D[1,1]).

|       |  ε   |  S   |  A   |
| :---: | :--: | :--: | :--: |
| **ε** |  0   |  1   |  2   |
| **S** |  1   |  0   |      |
| **U** |  2   |  1   |      |

Теперь посмотрим на ячейку D[1,2], переход из S в SA. Да, именно, стоимость перехода будет равна стоимости добавления буквы A и перехода из S в S, итого единица.

|       |  ε   |  S   |  A   |
| :---: | :--: | :--: | :--: |
| **ε** |  0   |  1   |  2   |
| **S** |  1   |  0   |  1   |
| **U** |  2   |  1   |      |

Последняя ячейка, D[2,2], переход из SU в SA. Самым оптимальным решением было бы заменить букву U на букву A, плюс цена бесплатного перехода из S в S. 

|       |  ε   |  S   |  A   |
| :---: | :--: | :--: | :--: |
| **ε** |  0   |  1   |  2   |
| **S** |  1   |  0   |  1   |
| **U** |  2   |  1   |  1   |

В самой правой нижней ячейке содержится финальная стоимость перехода из слова SU в слово SA. Аналогичным образом можно заполнить всю таблицу! Великолепно, из ячейки D[6,8] мы узнали, что переход из слова SUNDAY в слово SATURDAY стоит минимум три операции. Жирным шрифтом выделим оптимальный путь. 

Давайте проследим его по шагам. Переход из S в S ничего не стоит. Переход из S в SA стоит одну операцию. Переход из S в SAT стоит две операции. Переход из SU в SATU стоит две операции. Переход из SUN в SATUR стоит три операции. Переход из SUND в SATURD стоит три операции (стоимость предыдущего перехода плюс нулевая цена перехода из D в D). Переход из SUNDA в SATURDA стоит три операции. Наконец, переход из SUNDAY в SATURDAY требует тех же трёх операций.

Кстати, если присмотреться к табличке, то можно заметить, что оптимальных решений несколько: из D[1,2] можно перейти как в D[1,3], так и в D[2,2]. В этой постановке задачи нас интересует только минимальное количество, а не список всех возможных путей решения, так что это не суть важно.

|       |  ε   |   S   |   A   |   T   |   U   |   R   |   D   |   A   |   Y   |
| :---: | :--: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| **ε** |  0   |   1   |   2   |   3   |   4   |   5   |   6   |   7   |   8   |
| **S** |  1   | **0** | **1** | **2** |   3   |   4   |   5   |   6   |   7   |
| **U** |  2   |   1   |   1   |   2   | **2** |   3   |   4   |   5   |   6   |
| **N** |  3   |   2   |   2   |   2   |   3   | **3** |   4   |   5   |   6   |
| **D** |  4   |   3   |   3   |   3   |   3   |   4   | **3** |   4   |   5   |
| **A** |  5   |   4   |   3   |   4   |   4   |   4   |   4   | **3** |   4   |
| **Y** |  6   |   5   |   4   |   4   |   5   |   5   |   5   |   4   | **3** |

Вот так, собственно, и выглядит большинство решений из мира динамического программирования. Кстати, это решение имеет название — алгоритм Вагнера-Фишера. Забавный факт: этот алгоритм практически параллельно опубликовали разные группы незнакомых учёных с разных концов планеты, в эпоху, когда ещё и интернета не было. Товарищи Вагнер и Фишер, кстати, были далеко не первыми.

Давайте теперь рассмотрим, в чем его отличия от решения перебором.

### Анализ решения

Как уже было сказано, наивное решение этой задачи простой рекурсией имеет временную сложность O(3^n), но не требует лишней памяти — значит, O(1) по памяти. 

Какие издержки у динамического решения? Для простоты, давайте представим, что сравниваются слова равной длины, по n символов в слове. Всё решение сводится к заполнению таблицы с n+1 строчками (отдельная для пустой строки ε), и n+1 столбиками. Значит, используется (n+1)^2 ячеек. Не будем считать копейки, и округлим количество ячеек до n^2. Для каждой ячейки мы будем проверять трёх её соседей, что требует константного времени O(1). Значит, на заполнение всей таблицы потребуется O(n^2) операций.

Какой будет расход памяти? Элементарно — по количеству ячеек! Получаем O(n^2) стоимости по памяти. 

Если слова разной длины, то можно либо смотреть по самому длинному, либо чуть-чуть усложнить формулу сложности. Например, если первое слово имеет длину n, а второе — m, то потребуется O(nm) времени и O(nm) памяти.



## Итог

Думаю, что основная идея динамического программирования должна прослеживаться в представленном примере: мы жертвуем солидным количеством памяти (O(nm) вместо O(1)), но получаем просто сумасшедший выигрыш во времени (O(nm) против O(3^n)). 

Для чистоты совести коротко перечислим все ключевые особенности динамического программирования.

**Преимущества**:

- Скорость: главное достоинство динамического программирования, вокруг которого мы танцуем с начала статьи. Нерешаемые задачи становятся решаемыми, в большинстве случаев — за квадратичное время!
- Элегантность: One Ring to rule them all — создание компактной системы из нескольких правил для заполнения таблицы гарантирует решение задачи на любых данных. Ни исключений, ни пограничных случаев, несколько строчек — и сложная проблема решена. Фантастика.
- Точность: так как алгоритм динамического программирования рассмотрит абсолютно все возможные варианты и сценарии, он гарантированно обнаружит самое оптимальное решение. Никакой потери точности, никакой аппроксимации. Если решение существует — оно будет найдено.  

**Проблематика**:

- Память: в большинстве случаев алгоритмы из динамического программирования стоят квадратичного потребления памяти, что само по себе в восторг не приводит никого.

- Когнитивная нагрузка: компактная система правил выглядит великолепно, но этот ланч не бесплатен — ведь для составления, или хотя бы понимания этих систем правил необходимо научиться “думать на динамическом программировании”. Это является причиной довольно спорной репутации динамического программирования.



## Области применения

Динамическое программирование, исходя из его достоинств и недостатков, совсем не теоретическая конструкция, не выходящая за рамки научных работ, совсем нет. Оно пользуется популярностью во многих прикладных областях. Чтоб не размазывать мысль о множестве разных наук, будь то прикладная математика, машиностроение, теории управления или прогнозирование финансовых данных, скажу пару слов только об одной.

Называется эта наука биоинформатикой. Если в двух словах — она исследует “оцифровывание” биологического материала, а так же хранение и анализ полученной информации. В этой науки сотни захватывающих аспектов, и она ставит перед разработчиками очень серьезные задачи, ведь данных невероятно много. Например, в геноме человека около трёх миллиардов пар нуклеотидов (кирпичиков ДНК). Одна пара обычно кодируется одним байтом, в итоге выходит около трёх миллиардов байт информации на один-единственный геном — три гигабайта данных на подопытного.

Один геном проблемы не делает — подумаешь, три гигабайта. Вот только геномы сами по себе малоинтересны, их нужно сравнивать с другими геномами. Чтоб обнаружить мутации в геноме конкретного человека, нужно сначала “выровнять” его с другими, референсными геномами (выровненными и размеченными заранее). Возможных вариантов этого выравнивания может быть огромное количество, но нужно найти самый правдоподобный из них. То есть вариант, у которого максимальная вероятность возникновения. Например, вариант с наименьшим количеством мутаций. Если принять во внимание, что генетический код обычно хранятся в виде очень длинных строк, состоящих из разных букв, то пример с Расстоянием Левенштейна начинает играть новыми красками. Эта задача, потенциально приводящая к комбинаторному взрыву, замечательно решается методами динамического программирования!

Если интересно, почитайте про Multiple Sequence Alignment (MSA): https://en.wikipedia.org/wiki/Multiple_sequence_alignment#Dynamic_programming

Это лишь один маленький и очень упрощенный пример. На самом деле, биоинформатика буквально живет динамическим программированием. Построение молекулярных деревьев, чтоб понять, как именно и в какой последовательности происходила эволюция? Динамическое программирование. Эффективный перевод генетической информации (например, из кусочка кожи) в длиннющую строку в базе данных? Динамическое программирование. Если 15 лет назад полное считывание генома (это называется секвенированием) имело себестоимость в десятки миллионов долларов, то сегодня эта услуга стоит одну-две тысячи долларов, и потихоньку дешевеет дальше. Этот скачок произошел не столько за счёт роста нашей вычислительной мощности, сколько за счёт появления эффективных алгоритмов. Такие дела.

